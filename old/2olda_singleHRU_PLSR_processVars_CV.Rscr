#!/opt/R-3.2.3/bin//Rscript

# ================================================================================ 
# Step 2a: Process a single HRUs for each variable (cross-validated); Used to 
#          determine which variable is most important for the predicted month and hru
#
# Created by S. Baker, June 2018
# ================================================================================ 
rm(list=ls())

# ## === Input Data
source("/home/sabaker/s2s/analysis/scripts/cfsv2_analysis/post_process/plsr/0_control_PLSRmdl.R")
beg.time         = Sys.time()
preds            = 1:length(var_ls)        # preds to include in prediction

print('starting...')

## === libraries
suppressMessages(library(lubridate))
suppressMessages(library(ncdf4))
suppressMessages(library(abind))
suppressMessages(library(OceanView))
suppressMessages(library(pls))
suppressMessages(library(dplyr))
suppressMessages(library(plyr))

##### ===== Load CFSv2 Data 
setwd(out_model_dir)
load(file = file_data)
nms = names(data_out)

## extract objects
pred_cfs = data_out[[nms[1]]]
grid = data_out[[nms[2]]]
var_nms = c(data_out[[nms[3]]], 'hru_cfs')
date_cfs = data_out[[nms[4]]]
rm(data_out)

## get lengths of vars 
Ntime           = length(pred_cfs[1,1,1,])
Nlat            = length(pred_cfs[1,1,,1])
Nlon            = length(pred_cfs[1,,1,1])
Nvar            = length(pred_cfs[,1,1,1])

## get overlapping indexes for lagged analysis
t_ind <- NULL
for (itime in 1:Ntime) {
  t_i = data.frame(matrix(which(as.Date(date_cfs) >= (as.Date(date_cfs[itime]) - l) & as.Date(date_cfs) <= (as.Date(date_cfs[itime]))),
               nrow = 1))
  colnames(t_i) <- paste0('X', seq(1:length(t_i)))
  t_ind = rbind.fill(t_ind, t_i)
}

### === average lagged variables loop through time
# takes a long time

## check if analysis is lagged and lagged data is saved yet
if (l > 0) {
  if (!file.exists(file_lag_in)){
    pred_avg = array(NA,dim=c(Nvar,Nlon,Nlat,Ntime))
    for (itime in 1:Ntime) {
      pred_avg[,,,itime]  = apply(pred_cfs[,,, na.omit(as.numeric(t_ind[itime,])) ], c(1,2,3),mean)
    }
    saveRDS(pred_avg, file = file_lag_in )
    
    pred_cfs = pred_avg
    rm(pred_avg)
  } else {
    pred_cfs = readRDS(file_lag_in)
  }
}


##### ===== Load NLDAS Data (obs)
setwd(TP_data)
file_nld   = nc_open(paste0('nldas.1_2.', pred_var, '.nc')) 

## Extract hru coordinates for NLDAS
hru_v   = ncvar_get(file_nld, "hru")  # hru
hruInd = which(hru_v == hru)

## read time and find overlapping index
time = ncvar_get(file_nld, "time")
date_nld = as.POSIXct((time - 7) * 86400, 
                      origin = '1980-01-01', tz = 'utc') #timeseries of day 1 of obs
ind_overlap = inner_join(data.frame(date = date_cfs), 
                         data.frame(date = date_nld, ind = 1:length(date_nld)), by = 'date')

## read variable and convert units
nld_df   = ncvar_get(file_nld, pred_var)[hruInd, unique(ind_overlap$ind)]
if (pred_var == 'prate') { nld_df = nld_df * 24 } ## convert mm/hr to mm/d
nc_close(file_nld)

##### ===== Load CFSv2 T & P prediction on HRU
file_pred   = nc_open(paste0('cfsv2.', wk, '.', pred_var, '.nc')) 
time_pred = ncvar_get(file_pred, "time")
hru_v   = ncvar_get(file_pred, "hru")  # hru
hruInd = which(hru_v == hru)

## get date and mearge
date_pred = as.POSIXct(as.Date(as.POSIXct(time_pred - 6*86400, 
                                          origin = '1970-01-01', tz = 'utc'))) #timeseries of day 1 in cst
df_date = data.frame(date = date_pred, ind = 1:length(date_pred))
ind_overlap = left_join(ind_overlap, df_date, by = 'date')
cfs_pred_df   = ncvar_get(file_pred, pred_var)[hruInd, ind_overlap$ind.y]
if (pred_var == 'prate') { cfs_pred_df = cfs_pred_df * 86400 } ## convert kg/m^2/s to mm/d
cfs_pred_df = data.frame(date = ind_overlap$date, var = cfs_pred_df)
cfs_pred_df = cfs_pred_df %>% group_by(date) %>% dplyr::summarise(var= mean(var)) # daily average

## Scale NLDAS variable
nldasVar      = scale(nld_df)
Ymean         = mean(nld_df)     # Mean nldasVar during training period
Ysd           = sd(nld_df)       # Standard deviation of nldasVar during training period


##### =====  get groups for validation?
date_v          = unique(ind_overlap$date)
date_v          = data.frame(date = date_v, mon = month(date_v), ind = 1:length(date_v))
date_val        = filter(date_v, mon == pred_mon)
Nval            = nrow(date_val)
Ngroups         = ceiling(Nval/Ntime_sub)
cutgroup        = sapply(1:Ngroups, function(j) c(rep(j,Ntime_sub)))[1:Nval] #not random
xvalindex       = split(date_val$ind, cutgroup) # validate on these indexes
Nsegments       = length(xvalindex)-1

##### ===== Arrange data for PLSR ===== ##### 
Alldata <- ind_pred <- NULL
for(ipred in preds){ # Start loop over selected predictors
  
  # if hru, do different than gridded vars
  if (var_nms[ipred] == 'hru') {
    pred_i = array(cfs_pred_df$var, dim = c(Ntime,1))
  } else {
    
    Ny = length(na.omit(unique(grid[ipred, 1,])))
    Nx = length(na.omit(unique(grid[ipred, 2,])))
    
    pred_i = array(0,dim=c(Ntime,Nx*Ny))
    
    for(ilon in 1:Nx){
      for(ilat in 1:Ny){
        pred_i[,(Ny * (ilon - 1) + ilat)]  = pred_cfs[ipred,ilon,ilat,]
      }
    }
  }
  
  # remove NAs (from SST or any other vars)
  t = which(!is.na(pred_i[1,]), TRUE)
  pred_i = pred_i[,t]
  
  # get beginning of data
  ind_pred = c(ind_pred, ncol(Alldata)) #last ind of var
  
  # For SST - get predictor in correct format
  if (var_nms[ipred] == 'sst') {
    df = na.omit(data.frame(y= grid[ipred ,1, ],  x = grid[ipred ,2,]))
    ## sst has NA's that need to be removed
    grid_sst = df[t,] #save grid
  }
  
  # bind data
  pred_i = scale(pred_i) # do for each var seperately
  Alldata   <- cbind(Alldata, pred_i) 
} 

# scale - necessary?
#ArrayCFSR        = scale(Alldata) #produces NAs
ind_pred         = c(0, ind_pred, ncol(Alldata))
lng = ind_pred[2:length(ind_pred)] - ind_pred[1:(length(ind_pred)-1)]


##### ===== Predicat - loop over each potential predictor ===== ##### 
print(paste(pred_var, '- PLSR for each variable in CV - Forecasting', wk, 'wk -', month.abb[pred_mon]))
print(paste('Lagged =', l))
df_out <- NULL
load = array(NA, dim = c(length(preds), Ngroups ,max(lng), Ncomp))
#cv_array = array(NA, dim = c(length(preds),Nval,2))

for (ipred in preds) {
  print(paste('Evaluating predictor', var_nms[ipred]))
  
  df_cv <- NULL
  
  pred_num = which(ipred == preds)
  beg = ind_pred[pred_num] + 1
  end = ind_pred[(pred_num+1)]
  
  for(igroup in 1:Ngroups){ # Start loop over groups
    
    ## Define predictand
    Ypredictand   = nldasVar[-xvalindex[[igroup]]]        # Observed nldasVar for the training period
    Yverif        = nldasVar[xvalindex[[igroup]]] #  [date_val$ind]  
    
    ## Extract predictors (separate training from verification dataset)
    Xtrain      = Alldata[, beg:end][-xvalindex[[igroup]],]
    
    ## verify on all Jans as basic test of skill... no CV
    Xverif      = Alldata[, beg:end][ xvalindex[[igroup]],]
    
    ## Fit PLSR model and predict! - from 'PredictPLSRCrossVal.R' function
    mydf        = data.frame(Ypredictand)
    mydf$X      = Xtrain
    
    ## perform PLSR
    # apply PLSR using function from 'PredictPLSRCrossVal.R' function
    # plsrmod     = plsr(Ypredictand ~ X, ncomp = Ncomp, data = mydf) #, method='simpls', validation = 'CV'
    plsrmod     = plsr(Ypredictand ~ X, ncomp = Ncomp, data = mydf, 
                       model = TRUE, x = TRUE, y = TRUE, #validation = 'CV',
                       segments=Nsegments, segment.type='consecutive', method='simpls')
    
    # collect loadings for each training period
    na.v = rep(NA, (max(lng) - (end-beg+1)))
    load[pred_num, igroup,,] = rbind(matrix(loadings(plsrmod)[,1:Ncomp], ncol = Ncomp), 
                                    matrix(rep(na.v, Ncomp), ncol = Ncomp))
    
    ## predict Y and save
    Yhat_ver    = predict(plsrmod, ncomp = Ncomp, Xverif, se.fit=T)
    df_cv = rbind(df_cv, cbind(Yverif, Yhat_ver))
    
  }
  # collect data from predictor
  df = data.frame(pred   = rep(ipred, Nval),
                  date   = date_val$date,
                  ind    = 1:Nval,
                  Y_plsr = df_cv[,2] * Ysd + Ymean, 
                  Y_cfs  = left_join(date_val, cfs_pred_df, by = 'date')$var,
                  Y_nld  = df_cv[,1] * Ysd + Ymean)
  df$Y_plsr   = ifelse(df$Y_plsr <0, 0, df$Y_plsr) # remove negatives
  df$res_plsr = df$Y_plsr - df$Y_nld
  df$res_cfs  = df$Y_cfs - df$Y_nld
  
  df_out = rbind(df_out, df)
  
  # print cor
  print(paste('Cor predictor =', round(cor(df$Y_plsr, df$Y_nld), digits = 4), 
              '; Raw Cor =', round(cor(df$Y_cfs, df$Y_nld), digits = 4)))
  
}
end.time = Sys.time() - beg.time


## replace sst grid
if (any(var_nms[preds] == 'sst')) {
  grid_n = array(NA, dim = c(2, length(grid[1,1,])))
  grid_n[1, ] = c(grid_sst[,1], rep(NA, (length(grid[1,1,]) - nrow(grid_sst))))
  grid_n[2, ] = c(grid_sst[,2], rep(NA, (length(grid[1,1,]) - nrow(grid_sst))))
  grid[which(var_nms == 'sst'),,] = grid_n
}


## save results
setwd(allVar_model_dir)
data = list(df = df_out, load = load, run.time = end.time, vars_nms = var_nms[preds],
            grid = grid, ind_pred = ind_pred)
saveRDS(data, file = file_allVars)
print(paste('saved...', file_allVars))

print(paste('Simulation Time:', end.time))
