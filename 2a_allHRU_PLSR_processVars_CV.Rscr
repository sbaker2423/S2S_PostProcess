#!/opt/R-3.2.3/bin//Rscript

# ================================================================================ 
# Step 2a: Process all HRUs for each variable (cross-validated); Used to determine 
#          which variable is most important for the predicted month and hru
#
# Created by S. Baker, June 2018
# ================================================================================ 
rm(list=ls())

# ## === Input Data
source("/home/sabaker/s2s/analysis/scripts/cfsv2_analysis/post_process/plsr/0_control_PLSRmdl.R")
beg.time         = Sys.time()
preds            = 1:length(var_ls)        # preds to include in prediction
Nparallel       = 10

print('starting...')
print(beg.time)

## === libraries
suppressMessages(library(lubridate))
suppressMessages(library(ncdf4))
suppressMessages(library(abind))
suppressMessages(library(OceanView))
suppressMessages(library(pls))
suppressMessages(library(dplyr))
suppressMessages(library(plyr))
library(parallel)

##### ===== Load CFSv2 Data 
setwd(out_model_dir)
load(file = file_data)
nms = names(data_out)

## extract objects
pred_cfs = data_out[[nms[1]]]
grid = data_out[[nms[2]]]
var_nms = c(data_out[[nms[3]]], 'hru_cfs')
date_cfs = data_out[[nms[4]]]
rm(data_out)

## get lengths of vars 
Ntime           = length(pred_cfs[1,1,1,])
Nlat            = length(pred_cfs[1,1,,1])
Nlon            = length(pred_cfs[1,,1,1])
Nvar            = length(pred_cfs[,1,1,1])

## get overlapping indexes for lagged analysis
t_ind <- NULL
for (itime in 1:Ntime) {
  t_i = data.frame(matrix(which(as.Date(date_cfs) >= (as.Date(date_cfs[itime]) - l) & as.Date(date_cfs) <= (as.Date(date_cfs[itime]))),
                          nrow = 1))
  colnames(t_i) <- paste0('X', seq(1:length(t_i)))
  t_ind = rbind.fill(t_ind, t_i)
}

### === average lagged variables loop through time
# takes a long time (~20 mins)

## check if analysis is lagged and lagged data is saved yet
if (l > 0) {
  if (!file.exists(file_lag_in)){
    pred_avg = array(NA,dim=c(Nvar,Nlon,Nlat,Ntime))
    for (itime in 1:Ntime) {
      pred_avg[,,,itime]  = apply(pred_cfs[,,, na.omit(as.numeric(t_ind[itime,])) ], c(1,2,3),mean)
    }
    saveRDS(pred_avg, file = file_lag_in )
    
    pred_cfs = pred_avg
    rm(pred_avg)
  } else {
    pred_cfs = readRDS(file_lag_in)
  }
}

##### ===== Load NLDAS Data (obs)
setwd(TP_data)
file_nld   = nc_open(paste0('nldas.1_2.', pred_var, '.nc')) 
hru_v_nld   = ncvar_get(file_nld, "hru")  # hru

## read time and find overlapping index
time = ncvar_get(file_nld, "time")
date_nld = as.POSIXct((time - 7) * 86400, 
                      origin = '1980-01-01', tz = 'utc') #timeseries of day 1 of obs
ind_overlap = inner_join(data.frame(date = date_cfs), 
                         data.frame(date = date_nld, ind = 1:length(date_nld)), by = 'date')

## read variable and convert units
nld_all   = ncvar_get(file_nld, pred_var)[, unique(ind_overlap$ind)]
if (pred_var == 'prate') { nld_all = nld_all * 24 } ## convert mm/hr to mm/d
nc_close(file_nld)


### === Load CFSv2 T & P prediction on HRU
file_pred   = nc_open(paste0('cfsv2.', wk, '.', pred_var, '.nc')) 
time_pred = ncvar_get(file_pred, "time")
hru_v_cfs   = ncvar_get(file_pred, "hru")  # hru

## get date and mearge
date_pred = as.POSIXct(as.Date(as.POSIXct(time_pred - 6*86400, 
                                          origin = '1970-01-01', tz = 'utc'))) #timeseries of day 1 in cst
df_date = data.frame(date = date_pred, ind = 1:length(date_pred))
ind_overlap = left_join(ind_overlap, df_date, by = 'date')
cfs_pred_all   = ncvar_get(file_pred, pred_var)[ , ind_overlap$ind.y]
if (pred_var == 'prate') { cfs_pred_all = cfs_pred_all * 86400 } ## convert kg/m^2/s to mm/d
cfs_pred_all = data.frame(date = ind_overlap$date, var = as.data.frame(t(cfs_pred_all)))
cfs_pred_all = cfs_pred_all %>% group_by(date) %>% dplyr::summarise_all(funs(mean)) # daily average
cfs_date = cfs_pred_all$date
cfs_pred_all$date <- NULL

nc_close(file_pred)

### ===  get groups for validation
date_v          = unique(ind_overlap$date)
date_v          = data.frame(date = date_v, mon = month(date_v), ind = 1:length(date_v))
date_val        = filter(date_v, mon == pred_mon)
Nval            = nrow(date_val)
Ngroups         = ceiling(Nval/Ntime_sub)
cutgroup        = sapply(1:Ngroups, function(j) c(rep(j,Ntime_sub)))[1:Nval] #not random
xvalindex       = split(date_val$ind, cutgroup) # validate on these indexes
yvalindex       = split(1:Nval, cutgroup) 
Nsegments       = length(xvalindex)-1

### ===  hru split

#no_cores <- detectCores()

# Nhru            = ceiling(length(hru_v_nld)/Nparallel)
# cutHRU          = sapply(1:Nparallel, function(j) c(rep(j,Nhru)))[1:length(hru_v_nld)] 
# xvalindex       = split(hru_v_nld, cutHRU) # validate on these indexes



##### ===== Arrange data for PLSR ===== ##### 
Alldata <- ind_pred <- NULL
for(ipred in preds){ # Start loop over selected predictors

  Ny = length(na.omit(unique(grid[ipred, 1,])))
  Nx = length(na.omit(unique(grid[ipred, 2,])))
  
  pred_i = array(0,dim=c(Ntime,Nx*Ny))
  
  for(ilon in 1:Nx){
    for(ilat in 1:Ny){
      pred_i[,(Ny * (ilon - 1) + ilat)]  = pred_cfs[ipred,ilon,ilat,]
    }
  }
  
  
  # remove NAs (from SST or any other vars)
  t = which(!is.na(pred_i[1,]), TRUE)
  pred_i = pred_i[,t]
  
  # get beginning of data
  ind_pred = c(ind_pred, ncol(Alldata)) #last ind of var
  
  # For SST - get predictor in correct format
  if (var_nms[ipred] == 'sst') {
    df = na.omit(data.frame(y= grid[ipred ,1, ],  x = grid[ipred ,2,]))
    ## sst has NA's that need to be removed
    grid_sst = df[t,] #save grid
  }
  
  # bind data
  pred_i = scale(pred_i) # do for each var seperately
  Alldata   <- cbind(Alldata, pred_i) 
} 

## replace sst grid
if (any(var_nms[preds] == 'sst')) {
  grid_n = array(NA, dim = c(2, length(grid[1,1,])))
  grid_n[1, ] = c(grid_sst[,1], rep(NA, (length(grid[1,1,]) - nrow(grid_sst))))
  grid_n[2, ] = c(grid_sst[,2], rep(NA, (length(grid[1,1,]) - nrow(grid_sst))))
  grid[which(var_nms == 'sst'),,] = grid_n
}

# get index of data
ind_pred         = c(0, ind_pred, ncol(Alldata))
lng = ind_pred[2:length(ind_pred)] - ind_pred[1:(length(ind_pred)-1)]

grid_ls = list(grid = grid, ind = ind_pred, var_nms = var_nms)

# setwd(out_model_dir)
# saveRDS(grid_ls, file = 'grid_data.rds')

### ===  Setup Parallelization
library(foreach)
library(doParallel)
#cl<-makeCluster(Nparallel)

library(doSNOW)
cluster = makeCluster(Nparallel, type = "SOCK")
registerDoSNOW(cluster)

#hru_v_nld2 = hru_v_nld[1:20]
### ===  Loop through each hru
data_hrus = 
  foreach(hru_i = hru_v_nld, 
          .combine = list,
          .multicombine = T)  %dopar%   {

            #hru_i = hru_v_nld[1]
            
            # extract hru coordinates for NLDAS and CFSv2
            hruInd_nld = which(hru_v_nld == hru_i)
            hruInd_cfs = which(hru_v_cfs == hru_i)
            
            nld_df = nld_all[hruInd_nld,]
            cfs_pred_df = as.vector(cfs_pred_all[,hruInd_cfs])
            
            ## Scale NLDAS variable
            nldasVar      = scale(nld_df)
            Ymean         = mean(nld_df)     # Mean nldasVar during training period
            Ysd           = sd(nld_df)       # Standard deviation of nldasVar during training period

            ##### ===== Predicat - loop over each potential predictor ===== ##### 
            #print(paste(pred_var, '- PLSR for each variable in CV - Forecasting', wk, 'wk -', month.abb[pred_mon]))
            #print(paste('HRU:', hru_nm, '=', hru_i, '; number', hruInd_nld))
            print(paste('Lagged =', l, '- hru ', hru_i))
            df_out <- matrix(NA, ncol = 8, nrow = Nval*Nvar)
            load = array(NA, dim = c(length(preds), Ngroups ,max(lng), Ncomp))
            
            for (ipred in preds) {
              print(paste('Evaluating predictor', var_nms[ipred]))
              
              df_cv <- matrix(NA, ncol = 2, nrow = Nval) #NULL
              
              pred_num = which(ipred == preds)
              beg = ind_pred[pred_num] + 1
              end = ind_pred[(pred_num+1)]

              for(igroup in 1:Ngroups){ # Start loop over groups
                
                ## Define predictand
                Ypredictand   = nldasVar[-xvalindex[[igroup]]]        # Observed nldasVar for the training period
                Yverif        = nldasVar[xvalindex[[igroup]]] #  [date_val$ind]  
                
                ## Extract predictors (separate training from verification dataset)
                Xtrain      = Alldata[, beg:end][-xvalindex[[igroup]],]
                Xverif      = Alldata[, beg:end][ xvalindex[[igroup]],]
                
                ## Fit PLSR model and predict! - from 'PredictPLSRCrossVal.R' function
                mydf        = data.frame(Ypredictand)
                mydf$X      = Xtrain
                
                ## perform PLSR
                plsrmod     = pls::plsr(Ypredictand ~ X, ncomp = Ncomp, data = mydf, 
                                   model = TRUE, x = TRUE, y = TRUE, #validation = 'CV',
                                   segments=Nsegments, segment.type='consecutive', method='simpls')
                
                # collect loadings for each training period
                na.v = rep(NA, (max(lng) - (end-beg+1)))
                load[pred_num, igroup,,] = rbind(matrix(loadings(plsrmod)[,1:Ncomp], ncol = Ncomp), 
                                                 matrix(rep(na.v, Ncomp), ncol = Ncomp))
                
                ## predict Y and save
                Yhat_ver    = predict(plsrmod, ncomp = Ncomp, Xverif, se.fit=T)
                df_cv[yvalindex[[igroup]],] = cbind(Yverif, Yhat_ver)
                
              }
              # collect data from predictor
              df = data.frame(pred   = rep(ipred, Nval),
                              date   = date_val$date,
                              ind    = 1:Nval,
                              Y_plsr = df_cv[,2] * Ysd + Ymean, 
                              Y_cfs  = dplyr::left_join(date_val, cbind.data.frame(date = cfs_date, var = cfs_pred_df), by = 'date')$var,
                              Y_nld  = df_cv[,1] * Ysd + Ymean)
              df$Y_plsr   = ifelse(df$Y_plsr <0, 0, df$Y_plsr) # remove negatives
              df$res_plsr = df$Y_plsr - df$Y_nld
              df$res_cfs  = df$Y_cfs - df$Y_nld
              df_out[(Nval*(ipred - 1) + 1):(Nval*ipred),] = as.matrix(df)
              
              # print cor
              print(paste('Cor predictor =', round(cor(df$Y_plsr, df$Y_nld), digits = 4), 
                          '; Raw Cor =', round(cor(df$Y_cfs, df$Y_nld), digits = 4)))
              
            }

            ## save results
            list(hru = hru_i, df = df_out, load = load)
            
          }
stopCluster(cluster)

#names(data_hrus) <- hru_v_nld

end.time = Sys.time() - beg.time

## create list to save
#data = list(output = data_hrus, vars_nms = var_nms[preds], ind_pred = ind_pred, grid = grid)

## save results
setwd(allHRU_model_dir)
saveRDS(data_hrus, file = file_all)
print(paste('saved...', file_all))

print(paste('Simulation Time:', end.time))
